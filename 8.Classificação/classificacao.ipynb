{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifica√ß√£o \n",
    "# Descubrindo quem fez o ENEM 2016 apenas para treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns estudantes decidem realizar prova do ENEM de forma precoce, como um teste (coluna `IN_TREINEIRO`). Neste desafio, criaremos um modelo de classifica√ß√£o bin√°ria para tal feature, em que \"0\" √© considerado como n√£o realizou a prova de forma precoce e \"1\" √© considerado como realizou de forma precoce. Para tal, recorreremos ao modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Setup_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col='Unnamed: 0')\n",
    "test = pd.read_csv('test.csv')\n",
    "ids = test.NU_INSCRICAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vis√£o Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de Treino com 13730 observa√ß√µes e 166 colunas\n",
      "Dataset de Teste com 4570 observa√ß√µes e 43 colunas\n"
     ]
    }
   ],
   "source": [
    "print('Dataset de Treino com {0} observa√ß√µes e {1} colunas'.format(train.shape[0],train.shape[1]))\n",
    "print('Dataset de Teste com {0} observa√ß√µes e {1} colunas'.format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NU_INSCRICAO', 'NU_ANO', 'CO_MUNICIPIO_RESIDENCIA',\n",
       "       'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'SG_UF_RESIDENCIA',\n",
       "       'NU_IDADE', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA',\n",
       "       ...\n",
       "       'Q041', 'Q042', 'Q043', 'Q044', 'Q045', 'Q046', 'Q047', 'Q048', 'Q049',\n",
       "       'Q050'],\n",
       "      dtype='object', length=166)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NU_INSCRICAO', 'CO_UF_RESIDENCIA', 'SG_UF_RESIDENCIA', 'NU_IDADE',\n",
       "       'TP_SEXO', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO',\n",
       "       'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO', 'TP_DEPENDENCIA_ADM_ESC',\n",
       "       'IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ', 'IN_DISLEXIA',\n",
       "       'IN_DISCALCULIA', 'IN_SABATISTA', 'IN_GESTANTE', 'IN_IDOSO',\n",
       "       'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT',\n",
       "       'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'TP_LINGUA',\n",
       "       'TP_STATUS_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3',\n",
       "       'NU_NOTA_COMP4', 'NU_NOTA_COMP5', 'NU_NOTA_REDACAO', 'Q001', 'Q002',\n",
       "       'Q006', 'Q024', 'Q025', 'Q026', 'Q027', 'Q047'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO_ENTIDADE_CERTIFICACAO       12092\n",
       "CO_UF_ENTIDADE_CERTIFICACAO    12092\n",
       "SG_UF_ENTIDADE_CERTIFICACAO    12092\n",
       "Q041                           10792\n",
       "SG_UF_ESC                       9448\n",
       "TP_LOCALIZACAO_ESC              9448\n",
       "TP_SIT_FUNC_ESC                 9448\n",
       "CO_UF_ESC                       9448\n",
       "NO_MUNICIPIO_ESC                9448\n",
       "CO_MUNICIPIO_ESC                9448\n",
       "CO_ESCOLA                       9448\n",
       "TP_ENSINO                       9448\n",
       "TP_DEPENDENCIA_ADM_ESC          9448\n",
       "Q032                            7376\n",
       "Q031                            7376\n",
       "Q028                            7376\n",
       "Q033                            7376\n",
       "Q030                            7375\n",
       "Q029                            7375\n",
       "Q027                            7373\n",
       "NU_NOTA_COMP1                   3597\n",
       "NU_NOTA_LC                      3597\n",
       "NU_NOTA_REDACAO                 3597\n",
       "NU_NOTA_MT                      3597\n",
       "TP_STATUS_REDACAO               3597\n",
       "NU_NOTA_COMP5                   3597\n",
       "TX_RESPOSTAS_LC                 3597\n",
       "TX_RESPOSTAS_MT                 3597\n",
       "NU_NOTA_COMP4                   3597\n",
       "NU_NOTA_COMP3                   3597\n",
       "NU_NOTA_COMP2                   3597\n",
       "TX_GABARITO_MT                  3597\n",
       "TX_GABARITO_LC                  3597\n",
       "TX_RESPOSTAS_CN                 3389\n",
       "NU_NOTA_CN                      3389\n",
       "NU_NOTA_CH                      3389\n",
       "TX_RESPOSTAS_CH                 3389\n",
       "TX_GABARITO_CN                  3389\n",
       "TX_GABARITO_CH                  3389\n",
       "SG_UF_NASCIMENTO                 609\n",
       "CO_UF_NASCIMENTO                 609\n",
       "NO_MUNICIPIO_NASCIMENTO          609\n",
       "CO_MUNICIPIO_NASCIMENTO          609\n",
       "TP_ESTADO_CIVIL                  528\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()[train.isna().sum()>0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP_DEPENDENCIA_ADM_ESC    3144\n",
       "TP_ENSINO                 3144\n",
       "Q027                      2437\n",
       "NU_NOTA_REDACAO           1170\n",
       "NU_NOTA_COMP5             1170\n",
       "NU_NOTA_COMP4             1170\n",
       "NU_NOTA_COMP3             1170\n",
       "NU_NOTA_COMP2             1170\n",
       "NU_NOTA_COMP1             1170\n",
       "TP_STATUS_REDACAO         1170\n",
       "NU_NOTA_LC                1170\n",
       "NU_NOTA_CH                1112\n",
       "NU_NOTA_CN                1112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()[test.isna().sum()>0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©-processamento de Dados e Feature Engeenering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como extra√≠remos o resultado do dataset de teste, iremos filtrar o dataset de treino justamente com as features que o dataset de teste possui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = test.columns.tolist()\n",
    "features.append('IN_TREINEIRO')  # Manter a features 'IN_TREINEIRO' no Treino\n",
    "train = train[features]\n",
    "# Resever para o Alternativa - Feature Engeenering\n",
    "train2 = train.copy()\n",
    "test2 = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos conferir os dados faltantes (NAs) em termos absolutos e percentuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP_DEPENDENCIA_ADM_ESC    9448\n",
       "TP_ENSINO                 9448\n",
       "Q027                      7373\n",
       "NU_NOTA_REDACAO           3597\n",
       "NU_NOTA_COMP5             3597\n",
       "NU_NOTA_COMP4             3597\n",
       "NU_NOTA_COMP3             3597\n",
       "NU_NOTA_COMP2             3597\n",
       "NU_NOTA_COMP1             3597\n",
       "TP_STATUS_REDACAO         3597\n",
       "NU_NOTA_LC                3597\n",
       "NU_NOTA_CH                3389\n",
       "NU_NOTA_CN                3389\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()[train.isna().sum()>0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP_DEPENDENCIA_ADM_ESC    3144\n",
       "TP_ENSINO                 3144\n",
       "Q027                      2437\n",
       "NU_NOTA_REDACAO           1170\n",
       "NU_NOTA_COMP5             1170\n",
       "NU_NOTA_COMP4             1170\n",
       "NU_NOTA_COMP3             1170\n",
       "NU_NOTA_COMP2             1170\n",
       "NU_NOTA_COMP1             1170\n",
       "TP_STATUS_REDACAO         1170\n",
       "NU_NOTA_LC                1170\n",
       "NU_NOTA_CH                1112\n",
       "NU_NOTA_CN                1112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()[test.isna().sum()>0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP_DEPENDENCIA_ADM_ESC    0.688128\n",
       "TP_ENSINO                 0.688128\n",
       "Q027                      0.536999\n",
       "NU_NOTA_REDACAO           0.261981\n",
       "NU_NOTA_COMP5             0.261981\n",
       "NU_NOTA_COMP4             0.261981\n",
       "NU_NOTA_COMP3             0.261981\n",
       "NU_NOTA_COMP2             0.261981\n",
       "NU_NOTA_COMP1             0.261981\n",
       "TP_STATUS_REDACAO         0.261981\n",
       "NU_NOTA_LC                0.261981\n",
       "NU_NOTA_CH                0.246832\n",
       "NU_NOTA_CN                0.246832\n",
       "dtype: float64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()[train.isna().sum()>0].sort_values(ascending=False)/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP_DEPENDENCIA_ADM_ESC    0.687965\n",
       "TP_ENSINO                 0.687965\n",
       "Q027                      0.533260\n",
       "NU_NOTA_REDACAO           0.256018\n",
       "NU_NOTA_COMP5             0.256018\n",
       "NU_NOTA_COMP4             0.256018\n",
       "NU_NOTA_COMP3             0.256018\n",
       "NU_NOTA_COMP2             0.256018\n",
       "NU_NOTA_COMP1             0.256018\n",
       "TP_STATUS_REDACAO         0.256018\n",
       "NU_NOTA_LC                0.256018\n",
       "NU_NOTA_CH                0.243326\n",
       "NU_NOTA_CN                0.243326\n",
       "dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()[test.isna().sum()>0].sort_values(ascending=False)/test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos retirar as vari√°veis que possuem mais de 50% de dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO'], axis=1, inplace=True)\n",
    "test.drop(['TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos descartar as vari√°veis referentes as dados do question√°rio socioecon√¥mico, que s√£o pouco relevantes para a an√°lise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['NU_INSCRICAO','Q001', 'Q002', 'Q006', 'Q024','Q025', 'Q026', 'Q047'],axis=1, inplace=True)\n",
    "test.drop(['NU_INSCRICAO','Q001', 'Q002', 'Q006', 'Q024','Q025', 'Q026', 'Q047'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, dentre as vari√°veis com dados faltantas que ainda sobraram, n√≥s deixamos apenas as notas das diferentes provas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = test.isna().sum().sort_values(ascending=False)[test2.isna().sum()>0].index.tolist()\n",
    "remove = list(set(lista) - set(['NU_NOTA_LC','NU_NOTA_CH', 'NU_NOTA_CN',  'NU_NOTA_REDACAO']))\n",
    "train.drop(remove, axis=1, inplace=True)\n",
    "test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, imputamos a nota 0 para aqueles estudantes que faltaram √† prova (`TP_PRESENCA_XX` igual a 0) ou que foram eliminados (`TP_PRESENCA_XX` igual a 2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\codenation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#Para o treino\n",
    "train.NU_NOTA_CN.loc[train.TP_PRESENCA_CN == 0] = 0\n",
    "train.NU_NOTA_CN.loc[train.TP_PRESENCA_CN == 2] = 0\n",
    "train.NU_NOTA_CH.loc[train.TP_PRESENCA_CH == 0] = 0\n",
    "train.NU_NOTA_CH.loc[train.TP_PRESENCA_CH == 2] = 0\n",
    "train.NU_NOTA_LC.loc[train.TP_PRESENCA_LC == 0] = 0\n",
    "train.NU_NOTA_LC.loc[train.TP_PRESENCA_LC == 2] = 0\n",
    "train.NU_NOTA_REDACAO.loc[pd.isnull(train.NU_NOTA_REDACAO)] = 0\n",
    "\n",
    "#Para o teste\n",
    "test.NU_NOTA_CN.loc[test.TP_PRESENCA_CN == 0] = 0\n",
    "test.NU_NOTA_CN.loc[test.TP_PRESENCA_CN == 2] = 0\n",
    "test.NU_NOTA_CH.loc[test.TP_PRESENCA_CH == 0] = 0\n",
    "test.NU_NOTA_CH.loc[test.TP_PRESENCA_CH == 2] = 0\n",
    "test.NU_NOTA_LC.loc[test.TP_PRESENCA_LC == 0] = 0\n",
    "test.NU_NOTA_LC.loc[test.TP_PRESENCA_LC == 2] = 0\n",
    "test.NU_NOTA_REDACAO.loc[pd.isnull(test.NU_NOTA_REDACAO)] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto ao sexo dos participantes, apenas alteramos para o tipo da vari√°vel para que seja compat√≠vel com a leitura do algoritmo do modelo de classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexo= {'M':1,'F':2}\n",
    "train['TP_SEXO'] = pd.Series(sexo[item] for item in train['TP_SEXO'])\n",
    "test['TP_SEXO'] = pd.Series(sexo[item] for item in test['TP_SEXO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, realizamos o _One-hot Encoding_, que se trata de um t√©cnica de convers√£o de vari√°veis categ√≥ricas para vari√°veis num√©rica, de maneira que seja compat√≠vel com o algoritmo do modelo. Nesse caso, recorremos √† fun√ß√£o nativa do Pandas `get_dummies` que altera o dataframe transformando cada categoria espec√≠fica de cada vari√°vel categ√≥rica em uma _feature_ (uma coluna) no novo dataframe composto apenas dados bin√°rio, em que 0 corresponde √† aus√™ncia da categoria e 1 √† presen√ßa da categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Um problema frequente em modelos de classifica√ß√£o √© a quest√£o dos dados desbalanceados. O desbalan√ßo dos dados no caso da classifica√ß√£o pode gerar um vi√©s no modelo de modo que ele seja incapaz de captar a classe minorit√°ria (que √©, no caso, nosso interesse de an√°lise), uma vez que o modelo aprende espertamente que um novo dado se refere √† classe majorit√°ria simplesmente pela sua maior quantidade. \n",
    "   Por exemplo, diante de um dataset composto por uma classe majorit√°ria A, que representa em 96% dos dados, enquanto a classe minorit√°ria B representa apenas 4%, o modelo ir√° classificar um novo dado como sendo A, 96% das vezes, o que consiste num desempenho ilus√≥ria.\n",
    "   H√° duas maneiras de convertar nessa situa√ß√£o: Undersampling, removendo dados da classe majorit√°ria; Oversampling, reamostrando ados da classe minorit√°ria.\n",
    "   \n",
    "   No nosso caso, lan√ßacermos m√£o do oversampling, por meio do SMOTE. SMOTE se trata de uma t√©cnica que adiciona dados sint√©ticos √† classe minitorit√°ria atrav√©s da descoberta dos ùëò vizinhos mais pr√≥ximos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribui√ß√£o dos valores dos estudantes que fizeram o ENEM como um teste\n",
    "train.IN_TREINEIRO.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propor√ß√£o\n",
    "train.IN_TREINEIRO.value_counts()[1]/train.IN_TREINEIRO.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=\"minority\")\n",
    "X_smote, y_smote = smote.fit_resample(train.drop('IN_TREINEIRO', axis=1), train.IN_TREINEIRO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Random Forest consiste num algoritmo do tipo √°rvore de decis√£o, marcado pela t√©nica _bootstraping_ e pela subdivis√£o de features. A t√©cnica de bootstraping consiste em reamostrar o conjunto de treinamento com reposi√ß√£o e treinar um modelo para cada uma das reamostragens. Ap√≥s o treinamento dos v√°rios modelos, a classe prevista pela maioria dos modelos √© escolhida como classe final.\n",
    "\n",
    "A subdivis√£o de features se trata de subdividir as features usadas durante o treinamento das √°rvores de decis√£o. Dessa forma, a cada split da √°rvore de decis√£o, apenas um subconjunto das features √© considerado, o que constribui para a cria√ß√£o de  √°rvores mais variadas, e portanto, menos correlacionadas.Assim sendo, temos um erro total ainda menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = randomforest.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = pd.DataFrame({'NU_INSCRICAO':ids, 'IN_TREINEIRO':predict})\n",
    "resposta.to_csv('answer.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
